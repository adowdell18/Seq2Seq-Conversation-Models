{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Angry_Bot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7CNuAXoMY7Eh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"The current file is a modification of the following code sources\"\"\n",
        "/**************************************************\n",
        "* Title: Chatbot Startkit in TensorFlow 1.4\n",
        "* Author: Anacin, Luka\n",
        "* Date: 2017\n",
        "* Code version: 1.4\n",
        "* Availability: https://github.com/lucko515/chatbot-startkit\n",
        "***************************************************/\n",
        "\n",
        "/**************************************************\n",
        "* Title: seq2seq-chatbot\n",
        "* Author: Sanders, Avi\n",
        "* Date: 2018\n",
        "* Code version: n/a\n",
        "* Availability: https://github.com/AbrahamSanders/seq2seq-chatbot\n",
        "***************************************************/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owLNblxnVoe7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#import tensorflow as tf\n",
        "from tensorflow.python.layers.core import Dense\n",
        "\n",
        "#assert tf.__version__ == '1.4.0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLh7G9okTLGI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#import config\n",
        "#from model_utils import Chatbot\n",
        "#from cornell_data_utils import *\n",
        "from tqdm import tqdm\n",
        "import codecs\n",
        "import math\n",
        "import gensim\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EI_zu3o6z7c8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "fAG0_rxEWNfG",
        "colab_type": "code",
        "outputId": "cbafc09a-968f-4ae3-86f1-375069b975e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "#import config\n",
        "from collections import Counter\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D2MbX8pHZA2_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load Google's pre-trained Word2Vec model.\n",
        "#model = gensim.models.Word2Vec.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VjasBXMBz73X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "JvU6h7F7WTmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def grap_inputs():\n",
        "    '''\n",
        "\t\tThis function is used to define all tensorflow graph placeholders (inputs to the TF graph)\n",
        "\n",
        "\t\tInputs: None\n",
        "\n",
        "\t\tOutputs:\n",
        "\t\t\tinputs - questions in the case of a Chatbot with dimensions of None, None = batch_size, questions_length\n",
        "\t\t\ttargets - answers in the case of a Chatbot with dimensions of None, None = batch_size, answers_length\n",
        "\t\t\tkeep_probs - probabilities used in dropout layer\n",
        "\n",
        "\t\t\tencoder_seq_len -  vector which is used to define lenghts of each sample in the inputs to the model\n",
        "\t\t\tdecoder_seq_len - vector which is used to define lengths of each sample in the targets to the model\n",
        "\t\t\tmax_seq_len - target sample with the most words in it\n",
        "\n",
        "    '''\n",
        "    inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
        "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
        "    keep_probs = tf.placeholder(tf.float32, name='dropout_rate')\n",
        "    \n",
        "    encoder_seq_len = tf.placeholder(tf.int32, (None, ), name='encoder_seq_len')\n",
        "    decoder_seq_len = tf.placeholder(tf.int32, (None, ), name='decoder_seq_len')\n",
        "    \n",
        "    #encoder_seq_len = tf.placeholder(tf.int32, ([]), name='encoder_seq_len')\n",
        "    #decoder_seq_len = tf.placeholder(tf.int32, ([]), name='decoder_seq_len')\n",
        "    \n",
        "    max_seq_len = tf.reduce_max(decoder_seq_len, name='max_seq_len')\n",
        "    \n",
        "    return inputs, targets, keep_probs, encoder_seq_len, decoder_seq_len, max_seq_len\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "\n",
        "def encoders(inputs, rnn_size, number_of_layers, encoder_seq_len, keep_probs, encoder_embed_size, encoder_vocab_size):\n",
        "\n",
        "\t\n",
        "\t\t#Used to define encoder of the seq2seq model (The encoder is made of simple dynamic RNN network).\n",
        "\n",
        "\t\t#Inputs:\n",
        "\t\t\t#inputs -\n",
        "\t\t\t#rnn_siz - number of units in the RNN layer\n",
        "\t\t\t#number_of_layer - number of RNN layers that the model uses\n",
        "\t\t\t#encoder_seq_len - vector of lengths (got from placeholder)\n",
        "\t\t\t#keep_probs - dropout rate\n",
        "\t\t\t#encoder_embed_size - size of embedding vector for encoder part\n",
        "\t\t\t#encoder_vocab_size - number of different words that the model uses in a vocabulary\n",
        "\t\t\n",
        "\t\t#Outputs:\n",
        "\t\t\t#encoder_outputs -\n",
        "\t\t\t#encoder_states - internal states from the RNN layer(s)\n",
        "    \n",
        "    \n",
        "    \n",
        "    encoder_cell = tf.contrib.rnn.MultiRNNCell([cell(rnn_size, keep_probs) for _ in range(number_of_layers)])\n",
        "     \n",
        "    encoder_embedings = tf.contrib.layers.embed_sequence(inputs, encoder_vocab_size, encoder_embed_size) #used to create embeding layer for the encoder\n",
        "    \n",
        "    encoder_outputs, encoder_states = tf.nn.dynamic_rnn(encoder_cell, \n",
        "                                                        encoder_embedings, \n",
        "                                                        encoder_seq_len, \n",
        "                                                        dtype=tf.float32)\n",
        "    \n",
        "    return encoder_outputs, encoder_states\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "\n",
        "def cell(units, rate):\n",
        "        layer = tf.contrib.rnn.BasicLSTMCell(units)\n",
        "        return tf.contrib.rnn.DropoutWrapper(layer, rate)\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "\n",
        "def decoder_inputs_preprocessing(targets, word_to_id, batch_size):\n",
        "\t\n",
        "\t\t#Helper function used to prepare decoder inputs\n",
        "\n",
        "\t\t#Inputs:\n",
        "\t\t\t#targets -\n",
        "\t\t\t#word_to_id - dictionery that the model uses to map each word to it's int representation\n",
        "\t\t\t#batch_size - number of samples that we put through the model at onces\n",
        "\n",
        "\t\t#Outputs:\n",
        "\t\t\t#preprocessed version of decoder inputs\n",
        "\n",
        "    endings = tf.strided_slice(targets, [0, 0], [batch_size, -1], [1, 1]) #This line is used to REMOVE last member of each sample in the decoder_inputs batch\n",
        "    return tf.concat([tf.fill([batch_size, 1], word_to_id['<GO>']), endings], 1) #returning line and in this line we concat '<GO>' tag at the beginning of each sample in the batch\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def decoders(decoder_inputs, enc_states, dec_cell, decoder_embed_size, vocab_size,\n",
        "            dec_seq_len, max_seq_len, word_to_id, batch_size):\n",
        "\n",
        "\t\n",
        "\t\t\n",
        "\t\t#The decoder core function.\n",
        "    #Following comments Adapted from: https://github.com/AbrahamSanders/seq2seq-chatbot and Based on https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "\t\t#Inputs:\n",
        "\t\t\t#decoder_inputs -\n",
        "\t\t\t#enc_states - states created by the encoder part of the seq2seq network\n",
        "\t\t\t#dec_cell - RNN cell used in the decoder RNN (can be attention cell as well)\n",
        "\t\t\t#decoder_embed_size - vector size of the decoder embedding layer\n",
        "\t\t\t#vocab_size - number of different words used in the decoder part\n",
        "\t\t\t#dec_seq_len - vector of lengths for the decoder, obtained from the placeholder\n",
        "\t\t\t#max_seq_len - sample with max number of words (got from placeholder)\n",
        "\t\t\t#word_to_id - python dict used to encode each word to it's int representation\n",
        "\t\t\t#batch_size - number of samples that we put through the model at onces\n",
        "\n",
        "\t\t#Outputs:\n",
        "\t\t\t#train_dec_outputs -\n",
        "\t\t\t#inference_dec_output - Inportant for testing and production use!\n",
        "\t\n",
        "    \n",
        "    #Defining embedding layer for the Decoder\n",
        "    embed_layer = tf.Variable(tf.random_uniform([vocab_size, decoder_embed_size]))\n",
        "    embedings = tf.nn.embedding_lookup(embed_layer, decoder_inputs) \n",
        "    \n",
        "    #Creating Dense (Fully Connected) layer at the end of the Decoder -  used for generating probabilities for each word in the vocabulary\n",
        "    output_layer = Dense(vocab_size, kernel_initializer=tf.truncated_normal_initializer(0.0, 0.1))\n",
        "    \n",
        "\n",
        "    with tf.variable_scope('decoder'):\n",
        "        #Training helper used only to read inputs in the TRAINING stage\n",
        "        train_helper = tf.contrib.seq2seq.TrainingHelper(embedings, \n",
        "                                                          dec_seq_len)\n",
        "        \n",
        "        #Defining decoder - You can change with BeamSearchDecoder, just beam size\n",
        "        train_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, \n",
        "                                                        train_helper, \n",
        "                                                        enc_states, \n",
        "                                                        output_layer)\n",
        "        \n",
        "        #Finishing the training decoder\n",
        "        train_dec_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(train_decoder, \n",
        "                                                                    impute_finished=True, \n",
        "                                                                    maximum_iterations=max_seq_len)\n",
        "        \n",
        "    with tf.variable_scope('decoder', reuse=True): #we use REUSE option in this scope because we want to get same params learned in the previouse 'decoder' scope\n",
        "        #getting vector of the '<GO>' tags in the int representation\n",
        "        starting_id_vec = tf.tile(tf.constant([word_to_id['<GO>']], dtype=tf.int32), [batch_size], name='starting_id_vec')\n",
        "        \n",
        "        #using basic greedy to get next word in the inference time (based only on probs)\n",
        "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embed_layer, \n",
        "                                                                    starting_id_vec, \n",
        "                                                                    word_to_id['<EOS>'])\n",
        "        \n",
        "        #Defining decoder - for inference time\n",
        "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
        "                                                            inference_helper, \n",
        "                                                            enc_states, \n",
        "                                                            output_layer)\n",
        "        \n",
        "        \n",
        "        inference_dec_output, _, _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder, \n",
        "                                                                       impute_finished=True, \n",
        "                                                                       maximum_iterations=max_seq_len)\n",
        "        \n",
        "    return train_dec_outputs, inference_dec_output\n",
        "\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def attention_mech(rnn_size, keep_probs, encoder_outputs, encoder_states, encoder_seq_len, batch_size):\n",
        "    \n",
        "\t\t#The helper function used to create attention mechanism in TF 1.4\n",
        "\n",
        "\t\t#Inputs:\n",
        "\t\t\t#rnn_size - number of units in the RNN layer\n",
        "\t\t\t#keep_probs -  dropout rate\n",
        "\t\t\t#encoder_outputs - ouputs got from the encoder part\n",
        "\t\t\t#encoder_states - states trained/got from encoder\n",
        "\t\t\t#encoder_seq_len - \n",
        "\t\t\t#batch_size - \n",
        "\n",
        "\t\t#Outputs:\n",
        "\t\t\t#dec_cell - attention based decoder cell\n",
        "\t\t\t#enc_state_new -new encoder stated with attention for the decoder\n",
        "\n",
        "\n",
        "    #using internal function to easier create RNN cell\n",
        "    def cell(units, probs):\n",
        "        layer = tf.contrib.rnn.BasicLSTMCell(units)\n",
        "        return tf.contrib.rnn.DropoutWrapper(layer, probs)\n",
        "    \n",
        "    #defining rnn_cell\n",
        "    decoder_cell = cell(rnn_size, keep_probs)\n",
        "    \n",
        "    #using helper function from seq2seq sub_lib for Bahdanau attention\n",
        "    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(rnn_size, \n",
        "                                                               encoder_outputs, \n",
        "                                                               encoder_seq_len)\n",
        "    \n",
        "    #finishin attention with the attention holder - Attention Wrapper\n",
        "    dec_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, \n",
        "                                                   attention_mechanism, \n",
        "                                                   rnn_size/2)\n",
        "    \n",
        "    #Here we are usingg zero_state of the LSTM (in this case) decoder cell, and feed the value of the last encoder_state to it\n",
        "    attention_zero = dec_cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
        "    enc_state_new = attention_zero.clone(cell_state=encoder_states[-1])\n",
        "    \n",
        "    return dec_cell, enc_state_new\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def opt_loss(outputs, targets, dec_seq_len, max_seq_len, learning_rate, clip_rate):\n",
        "    \n",
        "\t\t#Function used to define optimizer and loss function\n",
        "\n",
        "\t\t#Inputs:\n",
        "\t\t\t#outputs - outputs got from decoder part of the network\n",
        "\t\t\t#targets - expected outputs/ labels\n",
        "\t\t\t#dec_seq_len -\n",
        "\t\t\t#max_seq_len - \n",
        "\t\t\t#learning_rate - small nubmer used to decrease value of gradients used to update our network\n",
        "\t\t\t#clip_rate - tolerance boundries for clipping gradients\n",
        "\n",
        "\t\t#Outputs:\n",
        "\t\t\t#loss -\n",
        "\t\t\t#trained_opt - optimizer with clipped gradients\n",
        "   \n",
        "    logits = tf.identity(outputs.rnn_output)\n",
        "    \n",
        "    mask_weigts = tf.sequence_mask(dec_seq_len, max_seq_len, dtype=tf.float32)\n",
        "    \n",
        "    with tf.variable_scope('opt_loss'):\n",
        "        #using sequence_loss to optimize the seq2seq model\n",
        "        loss = tf.contrib.seq2seq.sequence_loss(logits, \n",
        "                                                targets, \n",
        "                                                mask_weigts)\n",
        "        \n",
        "        #Define optimizer\n",
        "        opt = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "        #Next 3 lines used to clip gradients {Prevent gradient explosion problem}\n",
        "        gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "        clipped_grads, _ = tf.clip_by_global_norm(gradients, clip_rate)\n",
        "        traiend_opt = opt.apply_gradients(zip(clipped_grads, tf.trainable_variables()))\n",
        "        \n",
        "    return loss, traiend_opt\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "class Chatbot(object):\n",
        "    \n",
        "    def __init__(self, learning_rate, batch_size, enc_embed_size, dec_embed_size, rnn_size, \n",
        "                 number_of_layers, vocab_size, word_to_id, clip_rate):\n",
        "        \n",
        "        tf.reset_default_graph()\n",
        "        \n",
        "        self.inputs, self.targets, self.keep_probs, self.encoder_seq_len, self.decoder_seq_len, max_seq_len = grap_inputs()\n",
        "        \n",
        "        \n",
        "        enc_outputs, enc_states = encoders(self.inputs, \n",
        "                                          rnn_size,\n",
        "                                          number_of_layers, \n",
        "                                          self.encoder_seq_len, \n",
        "                                          self.keep_probs, \n",
        "                                          enc_embed_size, \n",
        "                                          vocab_size)\n",
        "        \n",
        "        dec_inputs = decoder_inputs_preprocessing(self.targets, \n",
        "                                                  word_to_id, \n",
        "                                                  batch_size)\n",
        "        \n",
        "        \n",
        "        decoder_cell, encoder_states_new = attention_mech(rnn_size, \n",
        "                                                          self.keep_probs, \n",
        "                                                          enc_outputs, \n",
        "                                                          enc_states, \n",
        "                                                          self.encoder_seq_len, \n",
        "                                                          batch_size)\n",
        "        \n",
        "        train_outputs, inference_output = decoders(dec_inputs, \n",
        "                                                  encoder_states_new, \n",
        "                                                  decoder_cell,\n",
        "                                                  dec_embed_size, \n",
        "                                                  vocab_size, \n",
        "                                                  self.decoder_seq_len, \n",
        "                                                  max_seq_len, \n",
        "                                                  word_to_id, \n",
        "                                                  batch_size)\n",
        "        \n",
        "        self.predictions  = tf.identity(inference_output.sample_id, name='preds')\n",
        "        \n",
        "        self.loss, self.opt = opt_loss(train_outputs, \n",
        "                                       self.targets, \n",
        "                                       self.decoder_seq_len, \n",
        "                                       max_seq_len, \n",
        "                                       learning_rate, \n",
        "                                       clip_rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dd7o4PdRnMU_",
        "colab_type": "code",
        "outputId": "97634e8a-5041-403c-c535-d29d2e23b866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1fX-ghPHWtsU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "\n",
        "VOCAB_THRESHOLD = 5\n",
        "\n",
        "\n",
        "BUCKETS = [ (50, 30)] #First try buckets you can tweak these\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "RNN_SIZE = 512\n",
        "\n",
        "NUM_LAYERS = 3\n",
        "\n",
        "ENCODING_EMBED_SIZE = 512\n",
        "DECODING_EMBED_SIZE = 512\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "LEARNING_RATE_DECAY = 0.9 #nisam siguran da cu ovo koristiti\n",
        "MIN_LEARNING_RATE = 0.0001\n",
        "\n",
        "KEEP_PROBS = 0.5\n",
        "\n",
        "CLIP_RATE = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUft6EgoWiK8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def get_conversations():\n",
        "\t\n",
        "\t\t\n",
        "\t\t#Function made ONLY for Cornell dataset to extract conversations from the raw file.\n",
        "\n",
        "\t\n",
        "\tconversations = []\n",
        "\twith open('raw_cornell_data/movie_conversations.txt', 'r') as f:\n",
        "\t\tfor line in f.readlines():\n",
        "\t\t\t\n",
        "\t\t\tconversation = line.split(' +++$+++ ')[-1]\n",
        "\t\t\tconversation = conversation.replace(\"'\", \"\")\n",
        "\t\t\tconversation = conversation[1:-2]\n",
        "\t\t\tconversation = conversation.split(\", \")\n",
        "\t\t\tconversations.append(conversation)\n",
        "\n",
        "\treturn conversations\n",
        "\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def get_movie_lines():\n",
        "\n",
        "\t\n",
        "\t\t#The helper function used to extract movie_lines from the Cornell dataset\n",
        "\n",
        "\t\n",
        "\tsentences = {}\n",
        "\twith open('raw_cornell_data/movie_lines.txt', 'r') as f:\n",
        "\t\tfor line in f.readlines():\n",
        "\t\t\tsentences[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1].replace('\\n', \"\")\n",
        "\n",
        "\treturn sentences\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def questions_vs_answers(convs, lines):\n",
        "\t\n",
        "\n",
        "\t\t#Save to the file questions and answers extracted from the raw files. VERSION 1\n",
        "\n",
        "\t\n",
        "\n",
        "\tfor i in range(len(convs)):\n",
        "\t\tconversation = convs[i]\n",
        "\t\tif len(conversation) % 2 == 0:\n",
        "\t\t\tfor line in range(len(conversation)):\n",
        "\t\t\t\tif line % 2 == 0:\n",
        "\t\t\t\t\twith open('movie_questions.txt', 'a') as f:\n",
        "\t\t\t\t\t\tf.write(lines[conversation[line]] + \"\\n\")\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\twith open('movie_answers.txt', 'a') as f:\n",
        "\t\t\t\t\t\tf.write(lines[conversation[line]] + \"\\n\")\n",
        "\n",
        "def questions_vs_answers_v2(convs, lines):\n",
        "\n",
        "\n",
        "\t\t#Save to the file questions and answers extracted from the raw files. VERSION 2\n",
        "\n",
        "\n",
        "\tfor i in range(len(convs)):\n",
        "\t\tconversation = convs[i]\n",
        "\t\tfor line in range(len(conversation) - 1):\n",
        "\n",
        "\t\t\twith open('movie_questions_2.txt', 'a') as f:\n",
        "\t\t\t\tf.write(lines[conversation[line]] + \"\\n\")\n",
        "\t\t\twith open('movie_answers_2.txt', 'a') as f:\n",
        "\t\t\t\tf.write(lines[conversation[line + 1]] + \"\\n\")\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def cornell_tokenizer(text):\n",
        "\t\n",
        "\t\t#Basic, starting tokenizer used for sentence preprocessing.\n",
        "\n",
        "\t\n",
        "\ttext = re.sub(r\"\\'m\", \" am\", text)\n",
        "\ttext = re.sub(r\"\\'s\", \" is\", text)\n",
        "\ttext = re.sub(r\"\\'re\", \" are\", text)\n",
        "\ttext = re.sub(r\"\\'ll\", \" will\", text)\n",
        "\ttext = re.sub(r\"\\'d\", \" would\", text)\n",
        "\ttext = re.sub(r\"won't\", \"will not\", text)\n",
        "\ttext = re.sub(r\"can't\", \"cannot\", text)\n",
        "\ttext = re.sub(r\"\\.\", \" . \", text)\n",
        "\ttext = re.sub(r\"\\?\", \" ? \", text)\n",
        "\ttext = re.sub(r\"!\", \" ! \", text)\n",
        "\ttext = re.sub(r\"/\", \" / \", text)\n",
        "\ttext = re.sub(r\",\", \" , \", text)\n",
        "\ttext = re.sub(r'\"', ' \" ', text)\n",
        "\ttext = re.sub(r\"-\", \" - \", text)\n",
        "\n",
        "\ttext = re.sub(r\"[-<>{}+=|?'()\\:@]\", \"\", text)\n",
        "\treturn text.replace('\\n', '')\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def clean_data():\n",
        "\t\n",
        "\t\t#Raw data clearner.\n",
        "\t\n",
        "\tcleaned_questions = []\n",
        "\tcleaned_answers = []\n",
        "  #cnt=0\n",
        "\twith codecs.open('gdrive/My Drive/movie_questions_2.txt', 'r', encoding = 'utf-8', errors = 'ignore') as f:\n",
        "    #str = unicode(str, errors='ignore')\n",
        "    #a.encode('utf-8').strip()\n",
        "\t\tlines = f.readlines()\n",
        "    \n",
        "\t\tfor line in lines:\n",
        "\t\t\tcleaned_questions.append(cornell_tokenizer(line))\n",
        "\n",
        "\twith codecs.open('gdrive/My Drive/movie_answers_2.txt', 'r', encoding = 'utf-8', errors = 'ignore') as f:\n",
        "\t\tlines = f.readlines()\n",
        " \n",
        "\t\tfor line in lines:\n",
        "     \n",
        "\t\t\tcleaned_answers.append(cornell_tokenizer(line))\n",
        "      \n",
        "\treturn cleaned_questions, cleaned_answers\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def clean_data_2():\n",
        "\t\n",
        "\t\t#Raw data clearner.\n",
        "\t\n",
        "\tcleaned_questions = []\n",
        "\tcleaned_answers = []\n",
        "  #cnt=0\n",
        "\twith codecs.open('angry_bot_questions.txt', 'r', encoding = 'utf-8', errors = 'ignore') as f:\n",
        "    #str = unicode(str, errors='ignore')\n",
        "    #a.encode('utf-8').strip()\n",
        "\t\tlines = f.readlines()\n",
        "    \n",
        "\t\tfor line in lines:\n",
        "\t\t\tcleaned_questions.append(cornell_tokenizer(line))\n",
        "\n",
        "\twith codecs.open('angry_bot_answers.txt', 'r', encoding = 'utf-8', errors = 'ignore') as f:\n",
        "\t\tlines = f.readlines()\n",
        " \n",
        "\t\tfor line in lines:\n",
        "     \n",
        "\t\t\tcleaned_answers.append(cornell_tokenizer(line))\n",
        "      \n",
        "\treturn cleaned_questions, cleaned_answers\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def create_vocab(questions, answers):\n",
        "\n",
        "\t\n",
        "\t\t\n",
        "\t\t#This function is used to create vocabulary, word_to_id and id_to_word dicts from cleaned data (got from the last question).\n",
        "\n",
        "\n",
        "\tassert len(questions) == len(answers)\n",
        "\tvocab = []\n",
        "\tfor i in range(len(questions)):\n",
        "\t\twords = questions[i].split()\n",
        "\t\tfor word in words:\n",
        "\t\t\tvocab.append(word)\n",
        "\n",
        "\t\twords = answers[i].split()\n",
        "\t\tfor word in words:\n",
        "\t\t\tvocab.append(word)\n",
        "\n",
        "\n",
        "\tvocab = Counter(vocab)\n",
        "\tnew_vocab = []\n",
        "\tfor key in vocab.keys():\n",
        "\t\tif vocab[key] >= VOCAB_THRESHOLD:\n",
        "\t\t\tnew_vocab.append(key)\n",
        "\n",
        "\tnew_vocab = ['<PAD>', '<GO>', '<UNK>', '<EOS>'] + new_vocab\n",
        "\n",
        "\tword_to_id = {word:i for i, word in enumerate(new_vocab)}\n",
        "\tid_to_word = {i:word for i, word in enumerate(new_vocab)}\n",
        "\n",
        "\treturn new_vocab, word_to_id, id_to_word\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def encoder(data, word_to_id, targets=False):\n",
        "\t\n",
        "\t\t#Using word_to_id dictionery to map each word in the sample to it's own int representation\n",
        "\n",
        "\t\n",
        "\tencoded_data = []\n",
        "\n",
        "\tfor i in range(len(data)):\n",
        "\n",
        "\t\tencoded_line = []\n",
        "\t\twords = data[i].split()\n",
        "\t\tfor word in words:\n",
        "\n",
        "\t\t\tif word not in word_to_id.keys():\n",
        "\t\t\t\tencoded_line.append(word_to_id['<UNK>'])\n",
        "\t\t\telse:\n",
        "\t\t\t\tencoded_line.append(word_to_id[word])\n",
        "\n",
        "\t\tif targets:\n",
        "\t\t\tencoded_line.append(word_to_id['<EOS>'])\n",
        "\n",
        "\t\tencoded_data.append(encoded_line)\n",
        "\n",
        "          \n",
        "\treturn np.array(encoded_data)\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def pad_data(data, word_to_id, max_len, target=False):\n",
        "\t\t#If the sentence is shorter then wanted length, pad it to that length\n",
        "\n",
        "\tif target:\n",
        "\t\treturn data + [word_to_id['<PAD>']] * (max_len - len(data))\n",
        "\telse:\n",
        "\t\treturn [word_to_id['<PAD>']] * (max_len - len(data)) + data\n",
        "\n",
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def bucket_data(questions, answers, word_to_id):\n",
        "\n",
        "\t\n",
        "\t\t#If you prefere bucketing version of the padding, use this function to create buckets of your data.\n",
        "\n",
        "\tassert len(questions) == len(answers)\n",
        "\n",
        "\tbucketed_data = []\n",
        "\talready_added = []\n",
        "\tfor bucket in BUCKETS:\n",
        "\t\tdata_for_bucket = []\n",
        "\t\tencoder_max = bucket[0]\n",
        "\t\tdecoder_max = bucket[1]\n",
        "\t\tfor i in range(len(questions)):\n",
        "\t\t\tif len(questions[i]) <= encoder_max and len(answers[i]) <= decoder_max:\n",
        "\t\t\t\tif i not in already_added:\n",
        "\t\t\t\t\tdata_for_bucket.append((pad_data(questions[i], word_to_id, encoder_max), pad_data(answers[i], word_to_id, decoder_max, True)))\n",
        "\t\t\t\t\talready_added.append(i)\n",
        "\n",
        "\t\tbucketed_data.append(data_for_bucket)\n",
        "    #print(bucketed_data)\n",
        "    #print(bucketed_data)\n",
        "\n",
        "\treturn bucketed_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UZY5KkGlTLGW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define get_accuracy helper function to check accuracy of the sequence data"
      ]
    },
    {
      "metadata": {
        "id": "WpuMIsoMTLGZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def get_accuracy(target, logits):\n",
        "    \"\"\"\n",
        "    Calculate accuracy\n",
        "    \"\"\"\n",
        "    max_seq = max(target.shape[1], logits.shape[1])\n",
        "    if max_seq - target.shape[1]:\n",
        "        target = np.pad(\n",
        "            target,\n",
        "            [(0,0),(0,max_seq - target.shape[1])],\n",
        "            'constant')\n",
        "    if max_seq - logits.shape[1]:\n",
        "        logits = np.pad(\n",
        "            logits,\n",
        "            [(0,0),(0,max_seq - logits.shape[1])],\n",
        "            'constant')\n",
        "\n",
        "    return np.mean(np.equal(target, logits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ikj098gjL0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def int2str(strings):\n",
        "    answer = ''\n",
        "    for i in strings:\n",
        "        if id_to_word[i] == 'i':\n",
        "            token = ' I'\n",
        "        elif id_to_word[i] == '<EOS>':\n",
        "            token = '.'\n",
        "        elif id_to_word[i] == '<OUT>':\n",
        "            token = 'out'\n",
        "        else:\n",
        "            token = ' ' + id_to_word[i]\n",
        "        answer += token\n",
        "        if token == '.':\n",
        "            break\n",
        "    return answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsxs-a_MTLGl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "metadata": {
        "id": "oby9BM6ETLGo",
        "colab_type": "code",
        "outputId": "420dab43-7220-4fd2-98cb-0e774fee3b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "cleaned_questions, cleaned_answers = clean_data()\n",
        "print(cleaned_questions[0:3])\n",
        "print(cleaned_answers[0:3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Can we make this quick    Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break   up on the quad .   Again . ', 'Well ,  I thought we would start with pronunciation ,  if that is okay with you . ', 'Not the hacking and gagging and spitting part .   Please . ']\n",
            "['Well ,  I thought we would start with pronunciation ,  if that is okay with you . ', 'Not the hacking and gagging and spitting part .   Please . ', 'Okay .  .  .  then how bout we try out some French cuisine .   Saturday    Night  ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cb451RuJpaH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "7CacPw55Jqqr",
        "colab_type": "code",
        "outputId": "c94220cb-3f8e-4e00-884e-a98de236a7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "cleaned_questions_2, cleaned_answers_2 = clean_data_2()\n",
        "print(cleaned_questions[0:3])\n",
        "print(cleaned_answers[0:3])\n",
        "print(len(cleaned_answers_2))\n",
        "print(len(cleaned_questions_2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Can we make this quick    Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break   up on the quad .   Again . ', 'Well ,  I thought we would start with pronunciation ,  if that is okay with you . ', 'Not the hacking and gagging and spitting part .   Please . ']\n",
            "['Well ,  I thought we would start with pronunciation ,  if that is okay with you . ', 'Not the hacking and gagging and spitting part .   Please . ', 'Okay .  .  .  then how bout we try out some French cuisine .   Saturday    Night  ']\n",
            "151\n",
            "155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2G2NuulCTLG2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating vocab and necessary dictionaries"
      ]
    },
    {
      "metadata": {
        "id": "T56e3BIWTLG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "vocab, word_to_id, id_to_word = create_vocab(cleaned_questions, cleaned_answers)\n",
        "#print(id_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2mpzOLuDTLHF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data encoding"
      ]
    },
    {
      "metadata": {
        "id": "bR0mjHmHTLHN",
        "colab_type": "code",
        "outputId": "aa38df3e-063e-4ae2-f868-6b9fea434e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2540
        }
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "encoded_questions = encoder(cleaned_questions_2, word_to_id)\n",
        "print(encoded_questions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[list([52, 168, 25, 136, 12094, 11147, 59, 3147, 21])\n",
            " list([252, 25, 363, 103, 9177, 29, 20, 1119, 5370, 280, 59, 2501, 1226, 24, 25, 76, 215, 300, 363, 1421, 2, 1222, 21, 252])\n",
            " list([252, 25, 12555, 29, 34, 24, 9247, 21, 689, 34, 136, 102, 379, 280, 124, 554, 258, 181, 19, 252])\n",
            " list([128, 541, 20, 1514, 714, 7, 554, 1323, 21, 52, 2607, 102, 2058, 59, 5133, 21])\n",
            " list([252, 2, 2, 24, 30, 34, 86, 853, 759, 29, 59, 10256, 24, 34, 69, 65, 438, 102, 2058, 59, 4988, 21, 25, 136, 102, 123, 34, 12251, 887, 359, 714, 114, 63, 363, 103, 34, 102, 103, 7068, 77, 21, 252])\n",
            " list([55, 541, 66, 2046, 21, 52, 363, 292, 102, 2185, 789, 56, 25, 125, 1758, 34, 21])\n",
            " list([252, 2, 2, 24, 34, 430, 151, 3137, 70, 7043, 31, 387, 21, 252])\n",
            " list([52, 12, 1940, 133, 190, 1344, 21, 25, 69, 65, 1833, 133, 2, 152, 66, 949, 7937, 21])\n",
            " list([252, 64, 160, 32, 181, 102, 174, 34, 24, 34, 12, 19, 59, 451, 252])\n",
            " list([252, 2, 2, 24, 34, 292, 102, 103, 278, 2118, 21, 146, 34, 12, 752, 102, 59, 5133, 32, 2, 133, 21, 605, 12, 302, 102, 663, 617, 5133, 24, 208, 6, 551, 1243, 3653, 21, 252])\n",
            " list([252, 2, 2, 24, 34, 168, 34, 12, 450, 438, 438, 433, 261, 1223, 24, 497, 450, 63, 21, 25, 86, 123, 262, 1028, 437, 34, 9, 207, 77, 7, 155, 968, 21, 252])\n",
            " list([252, 2, 2, 24, 20, 387, 34, 2, 29, 59, 5794, 32, 13097, 21, 52, 363, 103, 13767, 265, 6574, 133, 20, 359, 360, 88, 34, 125, 439, 2118, 61, 21, 252])\n",
            " list([820, 59, 8001, 77, 337, 21, 4857, 32, 949, 21])\n",
            " list([2, 2, 59, 3647, 32, 13097, 9, 63, 363, 208, 103, 2, 302, 77, 949, 21, 25, 363, 208, 486, 34, 1014, 1805, 18531, 9, 8988, 551, 607, 2, 262, 4196, 46, 79, 167, 3235, 21, 689, 2877, 6, 273, 3486, 21])\n",
            " list([261, 7, 12081, 34, 363, 103, 1454, 2776, 2, 18, 102, 9, 2125, 12886, 79, 7909, 9, 834])\n",
            " list([20473, 2463, 79, 3862, 29, 20720, 1873])\n",
            " list([59, 1415, 86, 2454, 70, 1816, 9485])\n",
            " list([2182, 13853, 59, 5133, 21])\n",
            " list([52, 12, 450, 1470, 970, 29, 59, 5133, 9, 20720, 1621, 21, 5318, 923, 34, 43, 3448, 955])\n",
            " list([52, 2055, 94, 34, 282, 885, 114, 34, 363, 103, 46, 152, 65, 714])\n",
            " list([252, 2, 30, 20720, 2, 59, 2438, 102, 7181, 1805, 2877, 27, 69, 1873, 407, 24, 34, 137, 31, 32, 433, 20, 387, 5, 8766, 789, 302, 21, 4841, 79, 20, 6325, 232, 20720, 14328, 24, 252])\n",
            " list([423, 30, 34, 538, 43, 102, 2665, 59, 10256, 92, 14, 4946, 523, 59, 337, 153, 5135, 59, 2, 29, 2180, 27, 2, 3468, 10240])\n",
            " list([261, 34, 6758, 102, 486, 59, 11381, 77, 337, 8129, 1013, 59, 2118, 153, 42, 5, 363, 69, 102, 552, 965, 248, 47, 5542, 21])\n",
            " list([2274, 759, 885, 9, 1832, 181, 46, 1330, 821, 19, 109, 2982, 21, 52, 12, 178, 536, 70, 1043, 9, 70, 3308, 21])\n",
            " list([1120, 2495, 29, 682, 2438, 32, 2074])\n",
            " list([252, 128, 32, 59, 1514, 9, 506, 3458, 24, 30, 25, 123, 34, 2970, 59, 5133, 7, 387, 61, 24, 25, 363, 69, 65, 590, 703, 199, 102, 45, 9, 119, 156, 453, 102, 828, 59, 1833, 70, 5794, 3497, 21, 252])\n",
            " list([64, 34, 12, 20, 4328, 21, 1606, 70, 1587, 2, 682, 6544, 102, 20, 1925, 21])\n",
            " list([723, 34, 287, 54, 2, 276, 52, 86, 1257, 102, 59, 5133, 92, 31, 21, 819, 3647, 32, 13097, 21, 74, 359, 714, 25, 277, 115, 92, 7, 437, 34, 5, 12, 181, 102, 69, 70, 2046, 21])\n",
            " list([252, 192, 25, 135, 447, 24, 34, 126, 208, 3491, 66, 5133, 92, 31, 21, 534, 25, 169, 69, 102, 676, 34, 536, 3191, 15728, 21, 252])\n",
            " list([2, 102, 20, 2, 21, 467, 276])\n",
            " list([25, 135, 447, 124, 32, 181, 19, 152, 59, 2495, 21, 2410, 9, 949, 12, 190, 3065, 141, 21, 25, 126, 208, 136, 102, 277, 31, 536, 14, 1090, 61, 21])\n",
            " list([52, 154, 887, 2105, 63, 885, 438, 433, 114, 17189, 4926, 34, 102, 20, 1119, 5370, 21])\n",
            " list([252, 261, 25, 836, 34, 4318, 92, 7, 61, 24, 167, 363, 103, 678, 7931, 21, 128, 32, 208, 43, 70, 5794, 3497, 430, 439, 21, 252])\n",
            " list([2468, 1013, 207, 3670, 359, 714, 21])\n",
            " list([146, 280, 34, 368, 20, 4328, 302, 133, 208, 13, 59, 5920, 852, 853, 276])\n",
            " list([252, 2, 2, 24, 557, 180, 538, 34, 93, 103, 158, 14, 20230, 2, 102, 66, 5133, 21, 297, 151, 6413, 59, 1104, 12079, 3647, 21, 252])\n",
            " list([52, 292, 102, 293, 43, 102, 3065, 59, 1621, 153, 9, 59, 949, 153, 114, 167, 363, 103, 7931, 21])\n",
            " list([252, 2, 24, 34, 292, 102, 679, 18, 21, 689, 208, 486, 59, 337, 1873, 11329, 29, 59, 949, 21, 252])\n",
            " list([25, 135, 447, 280, 59, 1873, 248, 337, 135, 8988, 70, 335, 152, 1931, 79, 20, 745, 5794, 34, 4328, 21, 52, 12, 160, 79, 20, 807, 11307, 152, 7, 21867, 21])\n",
            " list([3590, 92, 59, 2438, 9, 20, 21867, 69, 20, 438, 874, 280, 34, 21])\n",
            " list([305, 34, 92, 54, 102, 5747, 34, 102, 70, 7584, 52, 12, 70, 144, 7043, 9, 25, 135, 136, 102, 123, 480, 1070, 2713, 102, 34, 21])\n",
            " list([3700, 5133, 292, 102, 103, 2189, 92, 31, 102, 6, 215, 575, 1192, 21, 25, 1180, 1545, 31, 63, 32, 70, 355, 8116, 79, 2653, 102, 103, 2, 92, 31, 21])\n",
            " list([252, 25, 135, 447, 124, 59, 5133, 255, 24, 63, 32, 59, 2506, 102, 3150, 551, 24, 30, 575, 12, 1850, 7784, 988, 31, 32, 59, 67, 21, 252])\n",
            " list([252, 605, 257, 69, 1873, 24, 199, 34, 135, 123, 974, 1409, 551, 102, 949, 21, 261, 34, 125, 208, 1409, 63, 102, 949, 24, 1927, 714, 133, 70, 4061, 21, 252])\n",
            " list([2289, 714, 25, 277, 31, 34, 363, 103, 13986, 2, 21])\n",
            " list([252, 25, 135, 447, 124, 59, 2438, 469, 21, 25, 135, 447, 30, 34, 1277, 20, 850, 152, 20, 4061, 9, 89, 2222, 1777, 9, 34, 104, 86, 834, 59, 3224, 21, 261, 59, 2052, 1873, 289, 70, 2046, 302, 61, 24, 25, 76, 181, 102, 103, 59, 1779, 2046, 21, 252])\n",
            " list([252, 52, 12, 70, 5794, 3497, 24, 9, 63, 32, 280, 714, 34, 9239, 92, 160, 9, 1914, 2, 257, 59, 337, 2, 2158, 1013, 66, 21867, 276, 252])\n",
            " list([252, 25, 135, 447, 124, 32, 1890, 152, 59, 2052, 153, 24, 34, 363, 208, 379, 102, 59, 5133, 152, 31, 387, 276, 4773, 63, 46, 9, 126, 208, 2, 14297, 59, 5133, 276, 252])\n",
            " list([252, 25, 135, 447, 124, 59, 8001, 12, 21, 55, 32, 65, 1090, 102])\n",
            " list([923, 31, 2475, 79, 18257, 21, 252])\n",
            " list([25, 135, 447, 21, 128, 32, 20, 3353, 21, 11220, 29, 63, 21])\n",
            " list([52, 9, 59, 2438, 1457, 157, 34, 12, 70, 3457, 1149, 21, 55, 32, 20, 217, 1426, 59, 5133, 126, 208, 266, 102, 34, 21, 25, 76, 181, 102, 2737, 59, 834, 88, 34, 1462, 102, 4894, 59, 1252, 21])\n",
            " list([252, 58, 32, 59, 2046, 276, 52, 12, 4206, 77, 20, 5133, 24, 1684, 29, 59, 2438, 276, 689, 34, 12728, 47, 14554, 24, 34, 2162, 276, 252])\n",
            " list([89, 68, 205, 1711, 506, 401, 21, 21, 21])\n",
            " list([52, 430, 151, 6988, 77, 156, 152, 59, 5794, 92, 31, 21, 226, 126, 34, 168, 34, 12, 25, 76, 181, 102, 334, 34, 70, 14554, 972, 21])\n",
            " list([25, 76, 17525, 34, 198, 123, 70, 7584, 133, 6544, 5668, 21, 52, 292, 102, 94, 759, 885, 21])\n",
            " list([252, 34, 12, 493, 24, 17332, 208, 181, 102, 174, 20, 5133, 46, 152, 20, 1517, 873, 276, 252])\n",
            " list([629, 4134, 59, 1873, 77, 337, 133, 124, 34, 111, 255, 276, 55, 110, 415, 13097, 3647, 276])\n",
            " list([252, 146, 1167, 34, 1257, 102, 59, 5133, 31, 387, 21, 344, 32, 208, 638, 67, 31, 575, 68, 2454, 638, 2216, 24, 63, 32, 59, 67, 21, 406, 63, 32, 59, 67, 24, 34, 12, 181, 102, 94, 1013, 70, 987, 79, 1917, 9, 25, 76, 181, 102, 2737, 59, 834, 21, 252])\n",
            " list([252, 2493, 2, 2, 24, 59, 13068, 32, 7115, 9, 34, 2794, 583, 102, 949, 4103, 21, 25, 69, 65, 874, 43, 34, 69, 1129, 152, 20, 7190, 7, 1517, 199, 25, 4281, 102, 299, 31, 2, 21, 252])\n",
            " list([252, 2, 24, 59, 337, 153, 3955, 77, 337, 21, 52, 292, 102, 3065, 59, 337, 9, 949, 153, 21, 252])\n",
            " list([52, 292, 102, 293, 43, 102, 3065, 59, 337, 153, 9, 59, 949, 153, 276, 58, 25, 1006, 34, 126, 32, 13097, 276])\n",
            " list([128, 9464, 43, 4026, 79, 14, 2, 34, 12, 21, 25, 76, 965, 1222, 102, 2600, 34, 21])\n",
            " list([252, 2, 77, 160, 79, 59, 5133, 152, 1931, 79, 470, 32, 208, 2174, 21, 229, 430, 69, 955, 20, 217, 102, 34, 56, 34, 137, 124, 31, 3804, 92, 24, 199, 31, 32, 208, 124, 70, 1100, 3497, 90, 21, 252])\n",
            " list([261, 34, 528, 208, 70, 14237, 4328, 34, 2397, 27, 103, 887, 21, 25, 310, 43, 255, 34, 379, 31, 624, 1013, 8375, 14, 9815, 152, 20, 1514, 1833])\n",
            " list([23, 1827, 34, 27, 208, 69, 56, 609, 8001, 77, 337, 30, 34, 528, 70, 887, 3308, 21, 433, 94, 46, 79, 66, 2739, 21])\n",
            " list([839, 20, 804, 621, 21])\n",
            " list([25, 135, 137, 557, 34, 12, 114, 397, 34, 168, 3448, 33, 102, 3491, 59, 2, 152, 158, 70, 13855, 21, 261, 25, 277, 79, 34, 2970, 59, 2, 92, 7, 61, 25, 363, 6228, 14, 13866, 2232, 21])\n",
            " list([252, 25, 363, 1758, 34, 133, 59, 3647, 21, 2, 77, 59, 2, 152, 158, 70, 13855, 32, 13097, 276])\n",
            " list([252])\n",
            " list([252, 2182, 368, 70, 10017, 24, 888, 1339, 21, 612, 20, 749, 46, 79, 66, 2739, 21, 21924, 21, 252])\n",
            " list([252, 819, 3647, 554, 258, 5475, 133, 2656, 24, 9, 34, 69, 154, 2738, 79, 714, 102, 949, 595, 59, 451, 10256, 21, 25, 76, 208, 20, 118, 160, 557, 554, 811, 21, 406, 79, 7, 24, 34, 363, 103, 1940, 133, 190, 1344, 21, 52, 93, 992, 7, 2, 77, 2397, 14554, 252])\n",
            " list([3590, 92, 59, 1873, 11607, 437, 368, 77, 2425, 2994, 407, 147])\n",
            " list([74, 2625, 79, 59, 5133, 32, 70, 800, 13538, 79, 638, 13779, 21])\n",
            " list([43, 280, 2877, 10011, 59, 282, 9, 1084, 34, 70, 9815, 30, 2877, 277, 34, 138, 63, 61, 2877, 363, 828, 447, 79, 7, 1979, 152, 66, 2739, 21])\n",
            " list([252, 52, 2613, 59, 5794, 5441, 607, 208, 6354, 207, 2, 21, 52, 126, 208, 1232, 853, 79, 59, 3191, 21, 344, 32, 208, 682, 67, 133, 208, 13, 70, 2454, 3234, 63, 32, 1900, 21, 146, 34, 13986, 7, 110, 9612, 24, 2836, 1222, 363, 12728, 14292, 21, 252])\n",
            " list([252, 128, 1017, 79, 3647, 363, 208, 103, 2, 24, 2, 21, 819, 3147, 944, 59, 5133, 32, 13097, 9, 34, 363, 103, 2, 133, 20, 13855, 152, 600, 34, 69, 1584, 102, 873, 31, 5794, 9, 3491, 59, 5133, 21, 252])\n",
            " list([252, 2, 2, 24, 59, 9604, 32, 13854, 79, 14, 2, 9, 3515, 9612, 21, 2365, 77, 66, 2739, 152, 160, 2994, 133, 70, 2776, 14554, 21, 252])\n",
            " list([52, 168, 34, 12, 783, 77, 59, 331, 146, 126, 34, 168, 25, 1243, 25, 69, 102, 2, 70, 2, 557, 32, 332, 102, 103, 152, 4761, 9, 713, 20, 7784, 276])\n",
            " list([25, 126, 208, 447, 280, 59, 2052, 1873, 21, 297, 126, 208, 4814, 302, 21, 261, 34, 497, 16529, 77, 5920, 34, 363, 103, 152, 1917, 9, 2, 363, 208, 583, 59, 387, 21])\n",
            " list([2, 59, 3147, 6203, 9, 59, 7692, 32, 421, 1143, 438, 280, 433, 21, 43, 1167, 34, 2, 207, 2, 79, 20, 2645, 5794, 21, 1084, 59, 2438, 9, 5, 363, 94, 102, 20, 4562, 79, 7, 433, 21, 157, 34, 12, 160, 79, 20, 807, 2, 23136, 1035, 999, 1383, 21])\n",
            " list([252, 23, 24, 2, 59, 569, 12, 70, 800, 13782, 79, 59, 13779, 56, 617, 3115, 7252, 12, 19, 34, 536, 920, 536, 25, 76, 2821, 21, 252])\n",
            " list([128, 32, 208, 20, 1514, 714, 31, 5, 69, 230, 34, 17627, 46, 77, 70, 7043, 9, 30, 63, 1318, 61, 5, 363, 69, 102, 828, 2, 1222, 102, 119, 70, 278, 13145, 5177, 102, 20, 735, 21])\n",
            " list([252, 1083, 881, 24, 497, 18, 20, 144, 949, 9, 507, 696, 5133, 1954, 276, 252])\n",
            " list([252, 25, 135, 136, 59, 12094, 24, 111, 135, 368, 59, 2052, 1873, 102, 949, 29, 34, 21, 252])\n",
            " list([252, 5525, 24, 470, 554, 2052, 1873, 24, 31, 32, 65, 1426, 102, 828, 63, 46, 19, 160, 79, 59, 18531, 21, 25, 542, 887, 14292, 437, 66, 3191, 2, 21, 252])\n",
            " list([252, 2, 2, 24, 25, 9011, 5136, 20, 387, 34, 2237, 102, 59, 5133, 21, 25, 76, 181, 102, 1758, 34, 21, 252])\n",
            " list([146, 1167, 34, 1409, 59, 1621, 2, 102, 949, 9, 828, 63, 46, 19, 66, 5133, 21, 612, 70, 2665, 19, 759, 2, 21])\n",
            " list([344, 32, 59, 67, 31, 7, 32, 1890, 21, 423, 34, 430, 307, 3144, 114, 208, 77, 257, 21, 819, 2438, 32, 1925, 21, 100, 32, 208, 102, 4134, 21])\n",
            " list([252, 2, 2, 24, 397, 12, 34, 14255, 59, 2653, 437, 337, 102, 9149, 1013, 20, 12848, 24, 31, 32, 903, 9612, 21, 252])\n",
            " list([252, 25, 126, 208, 447, 280, 59, 1873, 77, 337, 24, 31, 32, 208, 66, 1378, 21, 84, 1378, 32, 20, 1441, 79, 2622, 5133, 21, 252])\n",
            " list([252, 261, 25, 277, 34, 379, 31, 387, 102, 1764, 2, 24, 25, 76, 181, 102, 6780, 4246, 1475, 59, 4325, 9, 3707, 59, 1966, 21, 16593, 21, 252])\n",
            " list([612, 2, 181, 280, 160, 79, 20, 13548, 102, 1522, 207, 79, 397, 300, 110, 2, 9, 518])\n",
            " list([25, 135, 447, 280, 59, 337, 8001, 21, 629, 1409, 551, 102, 949, 21, 839, 447, 79, 63, 19, 59, 451, 714, 9, 208, 77, 20, 9035, 79, 66, 5133, 21])\n",
            " list([52, 12, 2912, 276, 52, 4751, 840, 194, 834, 21, 52, 363, 123, 43, 2425, 59, 2438, 32, 106, 89, 2820, 280, 7, 21])\n",
            " list([52, 292, 102, 2614, 46, 70, 887, 387, 102, 15568, 29, 34, 5133, 114, 34, 12, 181, 102, 103, 152, 133, 70, 7844, 13784, 903, 1477, 9, 25, 363, 208, 2104, 34, 21])\n",
            " list([52, 292, 102, 299, 59, 3647, 9, 3491, 59, 5133, 887, 114, 25, 76, 181, 102, 6228, 31, 34, 12, 2, 133, 70, 1540, 79, 1082, 21])\n",
            " list([244, 34, 154, 1330, 1873, 152, 20, 921])\n",
            " list([252, 25, 296, 34, 9, 59, 2438, 949, 63, 46, 157, 30, 208, 24, 34, 12, 46, 79, 70, 881, 24, 3672, 21, 252])\n",
            " list([2, 30, 2877, 180, 836, 34, 9177, 102, 1764, 679, 92, 31, 61, 20, 1138, 363, 103, 20, 388, 79, 59, 5634, 21, 128, 1805, 32, 1927, 397, 34, 12, 13, 8001, 29, 59, 2438, 21])\n",
            " list([819, 2438, 430, 103, 278, 2742, 21])\n",
            " list([252, 3678, 950, 280, 59, 337, 153, 24, 6023, 18, 9, 103, 2118, 21, 252])\n",
            " list([252, 25, 135, 447, 280, 59, 1873, 24, 43, 280, 34, 439, 2118, 114, 2877, 363, 1758, 34, 9, 363, 119, 70, 387, 102, 94, 34, 14, 13866, 2232, 34, 497, 4318, 92, 70, 3074, 1149, 21, 252])\n",
            " list([252, 3678, 2031, 70, 267, 280, 59, 2438, 24, 89, 32, 1927, 2912, 102, 34, 17839, 21, 414, 212, 9, 6421, 19, 59, 949, 302, 21, 252])\n",
            " list([252, 689, 34, 136, 54, 102, 6988, 77, 34, 92, 34, 12, 2097, 77, 20, 5133, 423, 34, 111, 92, 2097, 24, 10333, 276, 25, 2272, 31, 32, 397, 59, 2438, 32, 1711, 77, 34, 276, 252])\n",
            " list([252, 344, 32, 208, 66, 881, 102, 1773, 280, 59, 1621, 1873, 24, 257, 25, 447, 280, 32, 31, 34, 12, 965, 447, 79, 66, 5133, 21, 252])\n",
            " list([252, 128, 32, 13097, 3647, 437, 70, 3497, 24, 34, 292, 102, 293, 102, 853, 759, 21, 25, 135, 447, 23294, 181, 19, 77, 337, 24, 31, 2376, 6863, 59, 949, 21, 252])\n",
            " list([52, 12, 970, 21, 819, 5794, 27, 208, 439, 92, 31, 30, 34, 528, 70, 887, 3497, 21, 629, 828, 46, 59, 2, 19, 551, 21])\n",
            " list([1099, 2, 31, 1827, 59, 2438, 32, 438, 3757, 63, 135, 631, 433, 5, 77, 70, 949, 7937, 9, 292, 34, 1775])\n",
            " list([252, 128, 32, 70, 2118, 7937, 24, 56, 840, 59, 2195, 2052, 1873, 77, 20, 325, 24, 5040, 17165, 276, 252])\n",
            " list([252, 2, 2, 24, 30, 25, 836, 34, 9177, 92, 7, 61, 102, 1764, 5441, 79, 7, 21867, 24, 25, 363, 6228, 34, 133, 13726, 21, 252])\n",
            " list([252, 55, 485, 118, 1735, 102, 54, 31, 34, 12, 70, 3468, 5814, 536, 70, 5794, 3497, 21, 261, 25, 123, 31, 61, 24, 34, 363, 103, 2, 21, 252])\n",
            " list([252, 52, 137, 557, 802, 70, 752, 102, 32, 34, 24, 94, 759, 9, 59, 569, 152, 336, 21, 25, 135, 136, 59, 12094, 21, 252])\n",
            " list([6779, 79, 124, 32, 181, 19, 152, 59, 2052, 153, 34, 126, 208, 1257, 102, 161, 5133, 92, 31, 21, 261, 34, 12, 13, 16644, 1873, 167, 12, 2738, 79, 13148, 6937, 102, 34, 9, 30, 34, 126, 208, 193, 551, 42, 31, 32, 59, 2046, 9, 208, 7, 21867, 32, 21])\n",
            " list([252, 261, 34, 379, 31, 387, 59, 2438, 20, 387, 34, 379, 102, 5920, 24, 25, 125, 123, 397, 59, 2438, 8734, 34, 92, 31, 21, 52, 430, 94, 70, 7542, 14554, 133, 43, 34, 3491, 59, 2438, 21, 252])\n",
            " list([252, 25, 1117, 59, 13779, 8618, 24, 30, 7, 32, 20, 1582, 34, 125, 126, 77, 2, 9, 1913, 59, 569, 252])\n",
            " list([252, 2, 2, 24, 34, 363, 103, 13767, 14, 18890, 2232, 21, 252])\n",
            " list([252, 2, 2, 24, 12, 34, 678, 819, 335, 153, 32, 111, 31, 24, 335, 21, 25, 135, 447, 124, 221, 79, 8001, 424, 112, 181, 19, 77, 337, 21, 819, 3647, 32, 13097, 9, 25, 76, 375, 14554, 34, 133, 63, 21, 128, 363, 208, 2713, 61, 24, 126, 34, 1192, 54, 252])\n",
            " list([3448, 59, 451, 67, 31, 59, 153, 3006, 9, 59, 2625, 102, 289, 278, 1104, 5541])\n",
            " list([74, 2501, 79, 59, 5133, 12, 70, 800, 13782, 79, 34, 9, 30, 638, 2216, 12, 208, 14451, 9485, 63, 32, 157, 34, 69, 2613, 551, 21])\n",
            " list([252, 52, 887, 2240, 7, 2, 18, 438, 433, 9, 94, 248, 2057, 21, 128, 541, 13088, 4211, 24, 486, 821, 152, 7, 2606, 21, 252])\n",
            " list([170, 32, 65, 1090, 133, 43, 34, 3491, 59, 569, 9, 292, 102, 949, 19, 391, 70, 887, 5814, 536, 70, 3497])\n",
            " list([52, 86, 828, 46, 59, 2052, 4285, 19, 59, 5133, 21, 52, 12, 19982, 29, 638, 1913, 21, 52, 94, 265, 1812, 7, 3651, 21])\n",
            " list([1062, 34, 12, 450, 438, 433, 32, 490, 1107, 114, 306, 480, 955, 21])\n",
            " list([252, 2, 2, 24, 2877, 135, 447, 124, 32, 181, 19, 77, 59, 337, 21, 52, 363, 208, 583, 102, 7, 7937, 9, 2, 262, 9691, 24, 126, 2877, 6, 273, 3486, 21, 252])\n",
            " list([344, 204, 631, 21, 55, 32, 208, 43, 34, 379, 102, 59, 2, 21])\n",
            " list([252, 2, 20, 387, 34, 4109, 102, 31, 7043, 32, 13097, 21, 344, 670, 31, 300, 541, 20, 8056, 160, 302, 24, 34, 12, 21, 252])\n",
            " list([252, 55, 7043, 541, 8056, 24, 34, 12, 133, 2234, 34, 125, 1257, 102, 156, 31, 387, 21, 252])\n",
            " list([2289, 714, 25, 277, 31, 34, 363, 103, 13986, 2, 21])\n",
            " list([252, 261, 25, 180, 277, 34, 1257, 102, 160, 79, 59, 5133, 31, 387, 61, 25, 363, 208, 9690, 102, 12486, 34, 46, 152, 1931, 79, 20, 2645, 18384, 24, 126, 25, 6, 273, 3486, 252])\n",
            " list([252, 261, 34, 3491, 59, 2, 92, 34, 126, 59, 5133, 24, 3448, 65, 330, 89, 204, 92, 34, 21, 252])\n",
            " list([74, 387, 34, 69, 258, 2970, 59, 5133, 32, 13097, 21, 2877, 135, 447, 280, 59, 1621, 153, 21, 34, 363, 103, 3066, 59, 191, 302, 88, 2, 133, 20, 359, 9041, 1344, 21])\n",
            " list([252, 261, 25, 123, 34, 752, 92, 31, 102, 70, 7043, 61, 24, 20694, 123, 102, 63, 31, 3448, 208, 111, 59, 2438, 1789, 34, 70, 374, 714, 21, 252])\n",
            " list([252, 58, 32, 970, 29, 34, 55, 32, 65, 387, 102, 379, 102, 20])\n",
            " list([5133, 21, 467, 24, 25, 136, 34, 102, 198, 248, 46, 167, 9])\n",
            " list([4151, 102, 31, 7043, 21, 252])\n",
            " list([252, 25, 126, 208, 447, 30, 34, 12, 16513, 46, 24, 34, 292, 102, 103, 2118, 77, 257, 3287, 21, 261, 7, 12081, 25, 363, 69, 102, 5424, 2, 1222, 21])\n",
            " list([252]) list([397, 32, 59, 2438, 1684, 29, 34])\n",
            " list([58, 25, 111, 6600, 110, 70, 514, 1540, 79, 2, 5404, 79, 70, 2, 21, 689, 208, 486, 54, 836, 34, 450, 115, 92, 31, 61, 21])\n",
            " list([252, 25, 135, 421, 137, 397, 25, 4322, 102, 2105, 34, 4155, 102, 379, 280, 7, 24, 34, 743, 137, 124, 34, 12, 450, 970, 21, 612, 248, 46, 167, 21, 252])\n",
            " list([52, 12, 4318, 2748, 9612, 9, 34, 292, 102, 497, 59, 337, 8001, 9950, 2, 21, 689, 25, 6, 273, 3486, 21])\n",
            " list([252, 6459, 46, 59, 2653, 19, 20, 569, 12079, 852, 34, 4513, 31, 34, 12, 5618, 13729, 9, 70, 7574, 24, 9, 25, 69, 65, 20563, 133, 504, 79, 2055, 771, 21, 252])\n",
            " list([252, 2, 2, 24, 34, 292, 102, 404, 63, 18, 24, 2, 21, 2405, 2, 380, 29, 63, 21, 5066, 453, 90, 21, 52, 1295, 56, 1548, 31, 34, 125, 94, 499, 29, 7371, 1391, 111, 157, 59, 2438, 2466, 59, 4285, 21, 2, 21, 252])\n",
            " list([52, 337, 1252, 4789, 102, 34, 21, 819, 569, 69, 955, 1118, 102, 4751, 20, 1014, 1805, 34, 334, 551, 111, 157, 34, 9, 59, 2438, 154, 47, 2, 433, 198, 499, 21])\n",
            " list([261, 2877, 180, 836, 114, 277, 280, 34, 2, 7371, 160, 79, 59, 5133, 152, 1931, 79, 20, 5794, 61, 34, 363, 103, 1745, 21])\n",
            " list([52, 292, 102, 4151, 102, 59, 7043, 21, 55, 32, 208, 4067, 1577, 5135, 8018, 102, 663, 59, 5133, 21, 2289, 714, 31, 1318, 34, 363, 103, 4056, 278, 2, 133, 59, 2501, 21])\n",
            " list([97, 20, 888, 27, 34, 168, 63, 32, 33, 102, 3491, 59, 2, 152, 158, 70, 13855, 21, 52, 528, 2, 21843, 9, 1798, 759, 187, 4026, 21, 612, 59, 439, 885, 21])\n",
            " list([252, 2, 2, 24, 34, 12, 70, 2, 19, 7, 2645, 12491, 21, 25, 125, 65, 1610, 2143, 102, 187, 77, 9355, 34, 9933, 54, 21, 52, 439, 92, 70, 1341, 106, 20095, 1391, 133, 306, 59, 4285, 2175, 21, 2365, 70, 679, 21, 252])\n",
            " list([252, 52, 12, 70, 3050, 24, 9, 34, 430, 137, 387, 887, 276, 25, 86, 240, 34, 12, 2, 949, 9, 59, 2052, 153, 276, 689, 887, 24, 114, 34, 12, 4654, 276, 252])\n",
            " list([25, 126, 208, 447, 30, 34, 69, 258, 13, 1873, 77, 337, 21, 344, 32, 59, 881, 102, 2058, 59, 5133, 22247, 199, 25, 69, 208, 618, 34, 450, 31, 276])\n",
            " list([344, 475, 31, 1784, 679, 32, 67, 21, 52, 12, 2510, 133, 617, 569, 9, 30, 34, 125, 208, 828, 447, 79, 70, 698, 2, 988, 34, 125, 208, 3497, 1107, 21])\n",
            " list([58, 19, 3313, 12, 34, 450, 58, 669, 34, 168, 34, 125, 3247, 152, 158, 14, 9612, 13855, 2, 79, 59, 5133, 363, 208, 103, 2, 21, 52, 363, 103, 2])\n",
            " list([252, 2, 2, 24, 124, 20, 749, 126, 34, 168, 34, 12, 450, 128, 541, 3423, 1913, 21, 461, 7, 2606, 5, 3491, 504, 29, 1082, 21, 192, 30, 5, 135, 34, 583, 102, 66, 2739, 9, 94, 7995, 92, 25, 76, 2970, 34, 438, 433, 24, 92, 70, 1341, 21, 252])\n",
            " list([1268, 1421, 31, 59, 7542, 3147, 32, 2, 14673, 152, 20, 5794, 9, 754, 551, 208, 136, 102, 6572, 1089, 133, 34])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M_O4ep2WTLHX",
        "colab_type": "code",
        "outputId": "abdb7bc1-ad6a-4d89-abea-4b901ecffb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2491
        }
      },
      "cell_type": "code",
      "source": [
        "#Adapted from: https://github.com/AbrahamSanders/seq2seq-chatbot and Based on https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "encoded_answers = encoder(cleaned_answers_2, word_to_id, True)\n",
        "print(encoded_answers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[list([252, 84, 3147, 32, 208, 20, 2046, 59, 32, 32, 276, 3])\n",
            " list([252, 3])\n",
            " list([58, 34, 86, 2044, 54, 102, 20, 1119, 5370, 21, 55, 32, 208, 525, 276, 3])\n",
            " list([64, 25, 135, 503, 70, 1846, 92, 34, 102, 7668, 257, 79, 66, 2282, 102, 3])\n",
            " list([25, 76, 208, 70, 2625, 536, 70, 3497, 21, 52, 12, 276, 3])\n",
            " list([25, 135, 292, 34, 2, 54, 25, 137, 43, 102, 126, 66, 881, 9, 497, 66, 4899, 152, 3310, 21, 3])\n",
            " list([25, 3812, 102, 103, 2, 607, 34, 21, 52, 135, 137, 20, 1514, 75, 280, 13779, 3])\n",
            " list([25, 68, 5691, 207, 21, 301, 154, 70, 2, 652, 682, 387, 21, 3])\n",
            " list([268, 1940, 25, 76, 59, 1582, 2, 9, 34, 12641, 63, 276, 3])\n",
            " list([25, 135, 292, 1107, 32, 174, 21, 229, 112, 7, 21, 3])\n",
            " list([23, 56, 920, 25, 76, 450, 9, 20, 6354, 9, 34, 12, 450, 1118, 199, 13858, 21, 3])\n",
            " list([252, 74, 1028, 32, 31, 25, 76, 70, 144, 3497, 9, 300, 32, 70, 2, 557, 802, 102, 94, 152, 3310, 2723, 24, 114, 300, 32, 46, 276, 252, 3])\n",
            " list([25, 76, 2143, 18, 3497, 9, 2, 25, 2334, 102, 103, 593, 337, 276, 3])\n",
            " list([52, 12, 70, 1122, 3497, 29, 65, 15229, 133, 59, 2, 276, 3])\n",
            " list([252, 1092, 24, 424, 1798, 759, 3486, 24, 199, 59, 6894, 6203, 276, 1832, 2097, 77, 54, 21, 252, 3])\n",
            " list([52, 86, 126, 31, 276, 229, 9210, 189, 593, 152, 66, 834, 9, 25, 2334, 102, 486, 63, 103, 13054, 621, 607, 20, 223, 79, 34, 276, 3])\n",
            " list([23, 42, 135, 1474, 46, 79, 66, 387, 9, 46, 79, 66, 2282, 21, 25, 137, 124, 25, 76, 450, 21, 3])\n",
            " list([301, 363, 607, 20, 714, 25, 76, 955, 29, 207, 21, 612, 46, 79, 66, 387, 9, 486, 54, 2665, 7, 3])\n",
            " list([252, 25, 76, 208, 13853, 551, 24, 25, 76, 6354, 551, 21, 973, 34, 1044, 137, 480, 280, 21, 252, 3])\n",
            " list([252, 52, 276, 52, 86, 663, 54, 480, 21, 52, 12, 70, 1122, 3497, 9, 5597, 759, 24, 20, 1032, 5449, 20, 1032, 21, 252, 3])\n",
            " list([612, 66, 282, 885, 25, 137, 43, 102, 126, 66, 881, 2291, 21, 25, 126, 70, 6998, 144, 881, 77, 63, 21, 3])\n",
            " list([146, 93, 34, 2, 54, 79, 10246, 2368, 10304, 66, 2438, 25, 76, 70, 9366, 3308, 21, 2073, 1122, 2, 789, 302, 135, 137, 13099, 21, 3])\n",
            " list([1282, 34, 135, 137, 2, 280, 66, 153, 21, 1753, 46, 79, 66, 2282, 21, 3])\n",
            " list([2877, 9210, 189, 2132, 79, 5542, 102, 66, 60, 21, 25, 363, 208, 486, 34, 828, 63, 499, 276, 3])\n",
            " list([146, 125, 34, 1084, 54, 70, 2625, 21, 124, 70, 3279, 3497, 34, 12, 21, 3])\n",
            " list([316, 31, 257, 34, 69, 102, 138, 25, 111, 5389, 18, 66, 745, 153, 102, 34, 21, 2412, 7582, 21, 3])\n",
            " list([64, 160, 789, 302, 125, 2600, 54, 21, 25, 76, 20, 1582, 7043, 424, 112, 21, 3])\n",
            " list([52, 6817, 3497, 276, 34, 69, 65, 438, 102, 1084, 54, 46, 79, 66, 60, 3])\n",
            " list([252, 3233, 79, 257, 135, 28, 65, 1873, 24, 363, 208, 103, 65, 1873, 21, 229, 112, 7, 21, 252, 3])\n",
            " list([1894, 54, 276, 723, 34, 1342, 21, 25, 76, 20, 1582, 679, 424, 112, 21, 3])\n",
            " list([64, 25, 363, 208, 4151, 21, 301, 32, 14, 4186, 9, 4751, 1470, 300, 112, 21, 3])\n",
            " list([561, 276, 1089, 42, 1832, 710, 54, 152, 302, 133, 6945, 14554, 9591, 34, 2598, 153, 21, 3])\n",
            " list([74, 1119, 5370, 554, 112, 1118, 19, 54, 21, 25, 137, 124, 2877, 76, 450, 21, 3])\n",
            " list([23, 43, 27, 34, 137, 43, 70, 2, 3497, 430, 439, 21, 52, 12, 70, 724, 3468, 3497, 759, 21, 3])\n",
            " list([25, 363, 21, 301, 32, 70, 1122, 7043, 9, 4441, 102, 103, 4924, 1013, 3310, 21, 25, 363, 663, 207, 21, 3])\n",
            " list([25, 76, 208, 20, 2, 34, 12, 257, 2, 2, 32, 557, 135, 4751, 54, 3])\n",
            " list([25, 76, 407, 144, 133, 617, 2, 9, 25, 76, 407, 144, 133, 7, 5794, 21, 52, 257, 135, 4751, 156, 92, 54, 21, 3])\n",
            " list([2289, 714, 34, 1084, 54, 152, 302, 133, 7, 221, 79, 14554, 21, 25, 363, 103, 23055, 34, 46, 21, 471, 8275, 34, 137, 21, 3])\n",
            " list([58, 221, 79, 679, 12, 34, 74, 223, 79, 34, 86, 663, 54, 1118, 280, 679, 9008, 21, 3])\n",
            " list([23, 397, 255, 34, 399, 54, 42, 34, 1122, 3497, 21, 1474, 46, 79, 66, 2282, 9, 840, 54, 102, 66, 881, 21, 3])\n",
            " list([23, 25, 112, 14, 874, 280, 34, 273, 21, 52, 86, 434, 54, 480, 46, 153, 34, 1122, 860, 368, 21, 3])\n",
            " list([164, 7584, 276, 629, 3491, 54, 92, 25, 76, 876, 21, 25, 76, 152, 66, 438, 172, 21, 20, 816, 79, 34, 292, 14554, 276, 3])\n",
            " list([2, 46, 25, 76, 208, 16513, 46, 34, 12, 276, 3])\n",
            " list([6991, 575, 59, 2, 232, 34, 5018, 551, 3710, 54, 64, 7, 32, 59, 67, 276, 3])\n",
            " list([146, 93, 34, 6228, 4061, 58, 70, 1122, 7584, 34, 12, 3])\n",
            " list([2, 1282, 34, 86, 126, 2, 29, 54, 21, 25, 363, 2665, 34, 21, 3])\n",
            " list([689, 34, 69, 70, 2438, 52, 135, 137, 480, 280, 20, 15852, 79, 2397, 21, 220, 59, 436, 32, 6945, 21, 3])\n",
            " list([2410, 2, 2158, 21, 25, 363, 923, 34, 47, 2158, 21, 3583, 102, 54, 92, 31, 61, 21, 3])\n",
            " list([74, 118, 160, 450, 1014, 13949, 789, 302, 32, 34, 1701, 276, 3])\n",
            " list([52, 12, 2513, 2291, 21, 629, 434, 54, 43, 102, 873, 66, 21867, 21, 3])\n",
            " list([74, 3353, 204, 4751, 156, 19, 66, 2475, 21, 3])\n",
            " list([124, 125, 34, 434, 54, 280, 13779, 21, 25, 135, 123, 34, 789, 302, 450, 124, 25, 126, 21, 52, 12, 70, 1122, 5814, 21, 3])\n",
            " list([723, 34, 1084, 54, 70, 2162, 52, 13273, 21, 25, 76, 70, 8431, 729, 679, 21, 3])\n",
            " list([58, 12, 34, 752, 280, 1753, 46, 79, 66, 2052, 153, 21, 3])\n",
            " list([25, 135, 4751, 7, 21, 25, 76, 407, 144, 133, 34, 257, 276, 3])\n",
            " list([10982, 2, 276, 25, 76, 208, 783, 21, 25, 76, 160, 79, 20, 1582, 3497, 32, 424, 112, 21, 3])\n",
            " list([58, 70, 3747, 5814, 34, 12, 21, 55, 32, 65, 387, 102, 1257, 102, 160, 79, 59, 1582, 569, 276, 3])\n",
            " list([25, 76, 208, 3652, 12094, 276, 128, 32, 66, 153, 679, 21, 52, 137, 124, 1474, 46, 79, 63, 276, 3])\n",
            " list([390, 749, 65, 276, 20720, 208, 2745, 66, 834, 21, 229, 237, 102, 374, 133, 7, 21, 2265, 19, 679, 25, 363, 828, 34, 102, 5490, 21, 3])\n",
            " list([52, 404, 9, 34, 12, 70, 1122, 1090, 133, 14, 7190, 3497, 21, 629, 34, 434, 54, 43, 102, 126, 66, 881, 3])\n",
            " list([52, 12, 208, 66, 16149, 21, 52, 135, 434, 54, 43, 102, 2665, 66, 2052, 153, 21, 3])\n",
            " list([64, 2291, 276, 52, 12, 20, 160, 17601, 14, 13097, 5814, 79, 13779, 21, 25, 76, 46, 79, 302, 21, 3])\n",
            " list([52, 86, 2600, 54, 21, 192, 30, 34, 126, 575, 363, 151, 103, 536, 144, 536, 54, 21, 3])\n",
            " list([146, 125, 34, 434, 54, 280, 1100, 13779, 276, 2, 59, 2, 189, 2339, 32, 208, 70, 144, 5814, 79, 13779, 21, 3])\n",
            " list([131, 7, 32, 397, 34, 12, 208, 2, 759, 276, 52, 69, 65, 874, 43, 63, 2016, 21, 1753, 46, 79, 66, 2397, 276, 3])\n",
            " list([25, 10336, 70, 887, 3308, 9, 3497, 988, 34, 363, 180, 103, 3])\n",
            " list([25, 135, 292, 70, 804, 621, 34, 126, 21, 3])\n",
            " list([25, 363, 13866, 2232, 34, 30, 34, 45, 54, 61, 21, 25, 76, 46, 79, 302, 21, 3])\n",
            " list([58, 32, 13097, 32, 59, 6894, 21, 612, 46, 79, 66, 1339, 276, 3])\n",
            " list([21924, 66, 729, 21, 25, 363, 923, 34, 276, 3])\n",
            " list([344, 32, 208, 59, 881, 102, 13525, 2397, 14554, 19, 34, 2, 21, 25, 137, 278, 280, 2, 988, 257, 79, 59, 13715, 9770, 21, 3])\n",
            " list([6908, 2994, 32, 20, 1582, 2994, 133, 59, 775, 276, 3])\n",
            " list([64, 63, 32, 70, 800, 13538, 79, 59, 13779, 276, 3])\n",
            " list([146, 280, 25, 10011, 34, 9, 923, 34, 43, 102, 379, 102, 70, 2143, 18, 21, 629, 34, 1084, 54, 70, 9815, 276, 3])\n",
            " list([52, 86, 14292, 54, 25, 76, 1118, 199, 70, 2118, 276, 3])\n",
            " list([52, 363, 208, 2, 54, 21, 25, 363, 2, 34, 21, 3])\n",
            " list([64, 25, 12542, 69, 102, 266, 102, 34, 21, 25, 137, 278, 988, 34, 126, 280, 368, 14, 2, 21, 629, 1117, 66, 2779, 21, 3])\n",
            " list([52, 135, 69, 70, 2790, 124, 13779, 32, 257, 280, 21, 122, 54, 198, 248, 9, 2665, 66, 5794, 21, 3])\n",
            " list([693, 20, 387, 34, 12, 752, 102, 54, 21, 25, 27, 92, 102, 123, 124, 59, 2052, 153, 2416, 92, 21, 52, 12, 2, 70, 2598, 153, 2057, 79, 949, 407, 3])\n",
            " list([819, 3147, 6203, 34, 12, 160, 79, 20, 807, 11307, 229, 873, 2889, 21, 25, 137, 124, 25, 76, 450, 21, 3])\n",
            " list([128, 32, 208, 19, 54, 21, 229, 258, 20, 1582, 75, 31, 32, 1323, 102, 7, 5794, 7, 32, 19, 34, 21, 3])\n",
            " list([261, 34, 135, 172, 59, 451, 2282, 21, 25, 363, 103, 2, 46, 19, 34, 359, 21, 3])\n",
            " list([370, 276, 25, 135, 292, 34, 102, 434, 54, 43, 102, 126, 66, 881, 21, 3])\n",
            " list([370, 276, 629, 94, 1013, 66, 2, 153, 21, 52, 135, 137, 480, 280, 66, 153, 21, 3])\n",
            " list([629, 7119, 34, 1873, 102, 1452, 21, 52, 135, 137, 480, 280, 66, 153, 21, 3])\n",
            " list([2, 54, 257, 804, 21, 3183, 34, 86, 663, 54, 480, 25, 135, 137, 21, 25, 76, 46, 79, 302, 21, 3])\n",
            " list([52, 94, 70, 2665, 2, 21, 809, 34, 230, 21, 64, 160, 1650, 34, 12, 158, 70, 312, 3497, 789, 302, 2055, 21, 3])\n",
            " list([252, 689, 34, 137, 66, 2438, 23, 24, 34, 135, 137, 43, 2, 89, 32, 114, 32, 208, 21, 252, 3])\n",
            " list([252, 463, 34, 775, 24, 25, 76, 70, 2118, 276, 252, 3])\n",
            " list([3700, 2, 12, 70, 3050, 21, 15768, 280, 31, 276, 3])\n",
            " list([261, 34, 379, 102, 54, 92, 31, 25, 76, 181, 102, 828, 34, 2057, 9, 923, 34, 2, 1100, 13779, 32, 257, 280, 21, 3])\n",
            " list([52, 430, 103, 2425, 102, 69, 54, 536, 70, 5794, 3497, 21, 25, 76, 20, 118, 160, 4266, 7, 21867, 2, 21, 3])\n",
            " list([97, 12, 34, 24126, 19, 66, 2052, 153, 55, 32, 2, 21, 3])\n",
            " list([468, 621, 679, 276, 25, 112, 7, 21, 3])\n",
            " list([25, 135, 292, 70, 1122, 2, 102, 2104, 54, 21, 25, 363, 2104, 273, 21, 3])\n",
            " list([252, 6183, 122, 54, 663, 34, 70, 698, 141, 280, 1082, 24, 438, 2057, 21, 252, 3])\n",
            " list([1146, 12, 34, 3646, 54, 79, 368, 14, 7759, 3])\n",
            " list([1753, 46, 79, 66, 2397, 2, 276, 3])\n",
            " list([252, 2197, 18, 24, 124, 12, 34, 450, 7787, 59, 2456, 152, 66, 2397, 252, 3])\n",
            " list([252, 2197, 18, 24, 12, 34, 3646, 66, 2438, 21, 52, 135, 421, 137, 212, 276, 252, 3])\n",
            " list([25, 76, 70, 4840, 679, 21, 25, 135, 292, 34, 1266, 54, 43, 102, 873, 66, 153, 21, 3])\n",
            " list([25, 76, 70, 2118, 21, 52, 12, 70, 3279, 5814, 759, 21, 3])\n",
            " list([612, 248, 34, 135, 137, 54, 92, 31, 114, 66, 2438, 21, 3])\n",
            " list([629, 34, 1257, 102, 54, 31, 387, 21, 25, 76, 70, 679, 79, 1082, 21, 3])\n",
            " list([23, 42, 1474, 79, 66, 1621, 2282, 21, 52, 135, 137, 1118, 280, 949, 153, 8641, 21, 3])\n",
            " list([1606, 20, 5618, 79, 2, 12, 9317, 102, 2665, 66, 1325, 21, 3])\n",
            " list([297, 154, 189, 2132, 79, 63, 652, 102, 551, 21, 3])\n",
            " list([25, 76, 1775, 248, 18, 621, 79, 54, 21, 3])\n",
            " list([629, 434, 54, 280, 2, 21, 25, 137, 43, 102, 126, 66, 881, 21, 3])\n",
            " list([52, 86, 9, 34, 363, 208, 6101, 54, 21, 3])\n",
            " list([52, 86, 2, 54, 276, 3])\n",
            " list([23, 42, 1832, 710, 54, 152, 302, 133, 617, 3279, 7519, 21, 3])\n",
            " list([2197, 18, 679, 21, 468, 18, 621, 79, 66, 2052, 153, 276, 3])\n",
            " list([25, 3491, 66, 2438, 29, 20, 3507, 1082, 133, 59, 775, 21, 3])\n",
            " list([297, 292, 70, 676, 852, 638, 2, 21, 128, 21867, 802, 102, 2573, 18, 789, 302, 21, 3])\n",
            " list([252, 2, 2232, 66, 2, 7, 21867, 802, 102, 2573, 18, 8, 24, 2723, 24, 9, 152, 70, 2885, 252, 3])\n",
            " list([4209, 63, 32, 56, 335, 97, 12, 34, 24126, 19, 63, 968, 21, 612, 46, 79, 302, 29, 31, 276, 3])\n",
            " list([52, 404, 276, 3])\n",
            " list([64, 34, 56, 1908, 3497, 276, 344, 32, 70, 800, 13782, 19, 34, 208, 54, 21, 3])\n",
            " list([4, 34, 4019, 70, 278, 13088, 5814, 79, 13779, 21, 425, 31, 32, 124, 25, 26, 21, 3])\n",
            " list([25, 76, 20, 1582, 5814, 79, 70, 3497, 7, 21867, 554, 618, 276, 3])\n",
            " list([64, 276, 25, 363, 208, 126, 63, 21, 3])\n",
            " list([25, 76, 20, 1582, 11861, 102, 7, 939, 21, 3])\n",
            " list([64, 34, 135, 21, 52, 12, 2, 54, 21, 52, 12, 70, 3747, 3497, 759, 21, 3])\n",
            " list([252, 390, 1089, 24, 126, 34, 69, 70, 887, 387, 21, 55, 32, 124, 25, 26, 21, 468, 621, 21, 252, 3])\n",
            " list([252, 64, 34, 12, 8056, 24, 34, 4328, 21, 252, 3])\n",
            " list([52, 12, 70, 9815, 276, 3])\n",
            " list([25, 363, 2665, 59, 729, 30, 34, 379, 102, 54, 92, 31, 61, 21, 3])\n",
            " list([425, 34, 1798, 759, 284, 3486, 276, 52, 12, 14, 2, 21, 3])\n",
            " list([84, 2438, 227, 387, 278, 280, 2, 18, 988, 34, 9, 59, 569, 276, 3])\n",
            " list([25, 363, 103, 59, 70, 13510, 1621, 679, 759, 21, 629, 3355, 59, 436, 21, 3])\n",
            " list([629, 379, 280, 66, 2438, 31, 387, 276, 3])\n",
            " list([25, 363, 208, 4151, 276, 3])\n",
            " list([52, 12, 19618, 54, 46, 278, 276, 3])\n",
            " list([3562, 79, 59, 2282, 276, 3])\n",
            " list([25, 76, 208, 5092, 70, 75, 21, 128, 5794, 802, 70, 2101, 152, 20, 729, 21, 3])\n",
            " list([64, 25, 76, 955, 133, 20, 804, 21, 2877, 76, 431, 257, 79, 7173, 21, 3])\n",
            " list([25, 76, 14, 2, 2118, 21, 629, 1117, 66, 2683, 3])\n",
            " list([34, 137, 124, 21, 25, 1243, 2, 607, 34, 438, 433, 21, 2877, 76, 46, 79, 302, 21, 3])\n",
            " list([3233, 79, 257, 66, 2438, 554, 1118, 102, 126, 29, 7, 21, 819, 5794, 3006, 21, 3])\n",
            " list([64, 25, 4814, 302, 111, 92, 470, 453, 21, 3])\n",
            " list([25, 363, 103, 16393, 34, 407, 21, 25, 363, 208, 103, 20, 118, 160, 306, 1745, 789, 302, 21, 3])\n",
            " list([170, 363, 208, 103, 70, 359, 714, 21, 25, 76, 306, 14948, 102, 1764, 5794, 21, 3])\n",
            " list([97, 20, 888, 27, 34, 168, 63, 32, 33, 102, 1117, 66, 2683, 21, 25, 76, 20, 1582, 3497, 424, 180, 154, 21, 3])\n",
            " list([34, 679, 18, 21, 52, 135, 137, 20, 1514, 75, 280, 815, 70, 21867, 21, 3])\n",
            " list([52, 86, 676, 54, 276, 7, 32, 20, 7190, 3209, 21, 3])\n",
            " list([25, 76, 70, 3497, 208, 70, 6162, 10227, 92, 34, 21, 3])\n",
            " list([52, 1041, 167, 21, 52, 135, 137, 124, 300, 255, 21, 3])\n",
            " list([629, 3645, 54, 79, 1805, 276, 3])\n",
            " list([58, 126, 34, 310, 276, 25, 76, 368, 70, 144, 3497, 21, 973, 34, 363, 151, 103, 21, 3])\n",
            " list([25, 363, 663, 34, 70, 2132, 280, 3147, 21, 3])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "inkokQC5TAX5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TESTING DECODER"
      ]
    },
    {
      "metadata": {
        "id": "zlo5t1PlS533",
        "colab_type": "code",
        "outputId": "d014763c-bba0-4986-b3b7-b4edcff7f4a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def convert_string2int(question, word2int):\n",
        "    question = cornell_tokenizer(question)\n",
        "    return [word2int.get(word, word2int['<UNK>']) for word in question.split()]\n",
        "quest = cleaned_questions_2[0]\n",
        "question = convert_string2int(quest, word_to_id)\n",
        "print(question)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[52, 168, 25, 136, 12094, 11147, 59, 3147, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wN3BUegOUuJH",
        "colab_type": "code",
        "outputId": "02ac2e71-b9be-4c6a-b277-2b5dfd524fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "def convert_int2string(answer, int2word):\n",
        "    #question = cornell_tokenizer(question)\n",
        "    answer = \" \".join([int2word.get(word, '<UNK>') for word in answer])\n",
        "    return answer\n",
        "#quest = cleaned_answers[0]\n",
        "answer = convert_int2string(question, id_to_word)\n",
        "#question = convert_string2int(quest, word_to_id)\n",
        "print(answer)\n",
        "#print(int2word)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You think I want excuses Fix your attitude .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JHmAlY6aTLHl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bucketting data"
      ]
    },
    {
      "metadata": {
        "id": "o_bqFCs9TLHp",
        "colab_type": "code",
        "outputId": "ebc23d7f-aeae-4488-eed7-d985c4a5ee26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "print(len(encoded_questions))\n",
        "print(len(encoded_answers))\n",
        "bucketed_data = bucket_data(encoded_questions, encoded_answers, word_to_id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "155\n",
            "151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-e4abf84c6159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_questions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbucketed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_answers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-bb09358b7e33>\u001b[0m in \u001b[0;36mbucket_data\u001b[0;34m(questions, answers, word_to_id)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m#If you prefere bucketing version of the padding, use this function to create buckets of your data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mbucketed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UDxCtxHNoq4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(bucketed_data[0][0][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IToR1i_XTLH2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating model object, session and defining model saver"
      ]
    },
    {
      "metadata": {
        "id": "T1fpmFygTLH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "model = Chatbot(LEARNING_RATE, \n",
        "                BATCH_SIZE, \n",
        "                ENCODING_EMBED_SIZE, \n",
        "                DECODING_EMBED_SIZE, \n",
        "                RNN_SIZE, \n",
        "                NUM_LAYERS,\n",
        "                len(vocab), \n",
        "                word_to_id, \n",
        "                CLIP_RATE) #4=clip_rate "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pkNR2nTFTLID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "session = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAr7f6WoTLIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "session.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nMNvNnFBTLIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver(max_to_keep=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0TUR74uTLIf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Entering big buckets, training loop"
      ]
    },
    {
      "metadata": {
        "id": "OdQv26HdlLSB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "import os\n",
        "\n",
        "check=os.listdir(\"gdrive/My Drive/checkpoint\")\n",
        "loadID=len(check)-1\n",
        "print(loadID)\n",
        "#check_points = listdir(\"gdrive/My Drive/checkpoint1/epoch{}/chatbot.ckpt\".format(loadID))\n",
        "#checkpt_loadID = len(check_points) - 1\n",
        "#barbie = os.listdir(\"gdrive/My Drive/checkpoint1/epoch0/chatbot.ckpt\")\n",
        "#saver.restore(session, barbie)\n",
        "if(loadID>-1):\n",
        "  #saver.restore(session, \"gdrive/My Drive/checkpoint1/epoch{}/chatbot.ckpt\".format(0))\n",
        "  check=os.listdir(\"gdrive/My Drive/checkpoint/epoch{}\".format(loadID))\n",
        "  BucketID=((len(check)-1)//3)-1\n",
        "  if(BucketID>-1):\n",
        "    saver.restore(session, \"gdrive/My Drive/checkpoint/epoch{}/chatbot_{}.ckpt\".format(loadID,BucketID))\n",
        "    BucketID=BucketID+1\n",
        "  else:\n",
        "    print(\"There is no checkpoint\")\n",
        "    loadID=0\n",
        "    BucketID=0\n",
        "  #for i in range (0, num_checkpts):\n",
        "    \n",
        " #   saver.restore(session,\"gdrive/My Drive/checkpoint1/epoch{}/chatbot_{}.ckpt\".format(loadID,i))\n",
        "  #saver.restore(session, \"gdrive/My Drive/checkpoint1/epoch{}/chatbot.ckpt\".format(loadID))\n",
        "else:\n",
        "  print(\"There is no checkpoint\")\n",
        "  loadID=0\n",
        "  BucketID=0\n",
        "  \n",
        "  #saver.restore(session, \"gdrive/My Drive/checkpoint1/epoch{}/checkpoint\".format(loadID)) ### only allowed to restore .ckpt files\n",
        "print(loadID,BucketID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wAs0-p0Ys0eZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  #check=os.listdir(\"gdrive/My Drive/test\")\n",
        "  #print(check)\n",
        "  #saver.restore(session, \"gdrive/My Drive/test/checkpoint\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DITMaE4780J2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ZjkIc5gCTLIi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "for i in range(0,EPOCHS):\n",
        "    epoch_accuracy = []\n",
        "    epoch_loss = []\n",
        "    for b in range(0,len(bucketed_data)):\n",
        "        bucket = bucketed_data[b]\n",
        "        questions_bucket = []\n",
        "        answers_bucket = []\n",
        "        bucket_accuracy = []\n",
        "        bucket_loss = []\n",
        "        for k in range(len(bucket)):\n",
        "            questions_bucket.append(np.array(bucket[k][0]))\n",
        "            answers_bucket.append(np.array(bucket[k][1]))\n",
        "        #for ii in tqdm(range(len(questions_bucket) //  BATCH_SIZE)):\n",
        "        Number_of_Loop = len(questions_bucket) / BATCH_SIZE\n",
        "        Number_of_Loop = math.trunc(Number_of_Loop)\n",
        "        for ii in tqdm(range(Number_of_Loop)):\n",
        "            \n",
        "        #for ii in tqdm(range(len(questions_bucket) //  BATCH_SIZE)):\n",
        "            \n",
        "            starting_id = ii * BATCH_SIZE\n",
        "            \n",
        "            X_batch = questions_bucket[starting_id:starting_id+BATCH_SIZE]\n",
        "            y_batch = answers_bucket[starting_id:starting_id+BATCH_SIZE]\n",
        "            \n",
        "            feed_dict = {model.inputs:X_batch, \n",
        "                         model.targets:y_batch, \n",
        "                         model.keep_probs:KEEP_PROBS, \n",
        "                         model.decoder_seq_len:[len(y_batch[0])]*BATCH_SIZE,\n",
        "                         model.encoder_seq_len:[len(X_batch[0])]*BATCH_SIZE}\n",
        "            \n",
        "            cost, _, preds = session.run([model.loss, model.opt, model.predictions], feed_dict=feed_dict)\n",
        "            \n",
        "            epoch_accuracy.append(get_accuracy(np.array(y_batch), np.array(preds)))\n",
        "            bucket_accuracy.append(get_accuracy(np.array(y_batch), np.array(preds)))\n",
        "            \n",
        "            bucket_loss.append(cost)\n",
        "            epoch_loss.append(cost)\n",
        "            #for s in preds:\n",
        "              #print(\"Chatbot: \",int2str(s))\n",
        "        #saver.save(session, \"gdrive/My Drive/checkpoint/epoch{}/chatbot_{}.ckpt\".format(i,b))    \n",
        "        print(\"Bucket {}:\".format(b+1), \n",
        "              \" | Loss: {}\".format(np.mean(bucket_loss)), \n",
        "              \" | Accuracy: {}\".format(np.mean(bucket_accuracy)))\n",
        "    BucketID=0\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPULdDWuo_mR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "for b in range(len(bucketed_data)):\n",
        "    bucket = bucketed_data[b]\n",
        "    print(len(bucket))\n",
        "    for l  in range (10):\n",
        "        print(l)\n",
        "        predicted_question=bucket[l][0]\n",
        "        question = ''\n",
        "        for i in predicted_question:\n",
        "            if id_to_word[i] == 'i':\n",
        "                token = ' I'\n",
        "            elif id_to_word[i] == '<EOS>':\n",
        "                token = '.'\n",
        "            elif id_to_word[i] == '<OUT>':\n",
        "                token = 'out'\n",
        "            else:\n",
        "                token = ' ' + id_to_word[i]\n",
        "            question += token\n",
        "            if token == '.':\n",
        "                break\n",
        "        print(question)\n",
        "        predicted_answer=bucket[l][1]\n",
        "        answer = ''\n",
        "        for i in predicted_answer:\n",
        "            if id_to_word[i] == 'i':\n",
        "                token = ' I'\n",
        "            elif id_to_word[i] == '<EOS>':\n",
        "                token = '.'\n",
        "            elif id_to_word[i] == '<OUT>':\n",
        "                token = 'out'\n",
        "            else:\n",
        "                token = ' ' + id_to_word[i]\n",
        "            answer += token\n",
        "            if token == '.':\n",
        "                break\n",
        "        print(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TfTnzYlXiMMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following code and comments are provided, sourced, and/or modified from the following repositories from: https://github.com/AbrahamSanders/seq2seq-chatbot; https://github.com/lucko515/chatbot-startkit; Retrieved on 10-04-2018\n",
        "########## PART 4 - TESTING THE SEQ2SEQ MODEL ##########\n",
        " \n",
        "#print(word_to_id)\n",
        "#cb = Chatbot()\n",
        " \n",
        "# Loading the weights and Running the session\n",
        "#checkpoint = \"./chatbot_weights.ckpt\"\n",
        "#checkpoint = os.listdir(\"gdrive/My Drive/checkpoint/epoch0/chatbot.ckpt\")\n",
        "'''\n",
        "session = tf.InteractiveSession()\n",
        "session.run(tf.global_variables_initializer())\n",
        "saver = tf.train.Saver()\n",
        "#saver.restore(session, checkpoint)\n",
        " '''\n",
        "bleu = []\n",
        "# Converting the questions from strings to lists of encoding integers\n",
        "def convert_string2int(question, word2int):\n",
        "    question = cornell_tokenizer(question)\n",
        "    return [word2int.get(word, word2int['<UNK>']) for word in question.split()]\n",
        " \n",
        "# Setting up the chat\n",
        "while(True):\n",
        "    question = input(\"You: \")\n",
        "    query = question\n",
        "    if question == 'Goodbye':\n",
        "      break\n",
        "    inBucket=0\n",
        "    outBucket=0\n",
        "    question = convert_string2int(question, word_to_id)\n",
        "    question = question + [word_to_id['<EOS>']]\n",
        "    if(len(question)<=10):\n",
        "        inBucket=10\n",
        "        outBucket=15\n",
        "    elif(len(question)<=15):\n",
        "        inBucket=15\n",
        "        outBucket=25\n",
        "    elif(len(question)<=25):\n",
        "        inBucket=25\n",
        "        outBucket=45\n",
        "    elif(len(question)<=45):\n",
        "        inBucket=45\n",
        "        outBucket=60\n",
        "    elif(len(question)<=60):\n",
        "        inBucket=60\n",
        "        outBucket=100\n",
        "    question =  [word_to_id['<PAD>']] * (inBucket - len(question)) + question\n",
        "    \n",
        "    #print(question)\n",
        "    #print(outBucket)\n",
        "    #print(inBucket)\n",
        "    #print(BATCH_SIZE)\n",
        "    #fake_batch = np.zeros((BATCH_SIZE, inBucket))\n",
        "    #fake_batch[0] = question\n",
        "    fake_batch=[question]*BATCH_SIZE\n",
        "    predicted_answer = session.run(model.predictions, {model.inputs: fake_batch, model.keep_probs: 0.5,\n",
        "                                  model.decoder_seq_len:[outBucket]*BATCH_SIZE,\n",
        "                                  model.encoder_seq_len:[inBucket]*BATCH_SIZE})\n",
        "    answer = ''\n",
        "    #print(predicted_answer)\n",
        "    for i in predicted_answer[0]:\n",
        "        if id_to_word[i] == 'i':\n",
        "            token = ' I'\n",
        "        elif id_to_word[i] == '<EOS>':\n",
        "            token = '.'\n",
        "        elif id_to_word[i] == '<OUT>':\n",
        "            token = 'out'\n",
        "        else:\n",
        "            token = ' ' + id_to_word[i]\n",
        "        answer += token\n",
        "        if token == '.':\n",
        "            break\n",
        "    print('ChatBot: ' + answer)\n",
        "    # shorter candidate\n",
        "  #from nltk.translate.bleu_score import sentence_bleu\n",
        "    reference_list = query.split(\" \")\n",
        "    candidate_list = answer.split(\" \")\n",
        "    print(reference_list)\n",
        "    print(candidate_list)\n",
        "    reference = [reference_list]\n",
        "    candidate = candidate_list\n",
        "    score = sentence_bleu(reference, candidate)\n",
        "    print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
